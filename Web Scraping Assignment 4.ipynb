{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99e85818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\data_science\\lib\\site-packages (4.1.3)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\data_science\\lib\\site-packages (from selenium) (0.9.2)\n",
      "Requirement already satisfied: urllib3[secure,socks]~=1.26 in c:\\data_science\\lib\\site-packages (from selenium) (1.26.4)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\data_science\\lib\\site-packages (from selenium) (0.20.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\data_science\\lib\\site-packages (from trio~=0.17->selenium) (2.3.0)\n",
      "Requirement already satisfied: outcome in c:\\data_science\\lib\\site-packages (from trio~=0.17->selenium) (1.1.0)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\data_science\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: sniffio in c:\\data_science\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\data_science\\lib\\site-packages (from trio~=0.17->selenium) (20.3.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\data_science\\lib\\site-packages (from trio~=0.17->selenium) (1.14.5)\n",
      "Requirement already satisfied: idna in c:\\data_science\\lib\\site-packages (from trio~=0.17->selenium) (2.10)\n",
      "Requirement already satisfied: pycparser in c:\\data_science\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.20)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\data_science\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.1.0)\n",
      "Requirement already satisfied: cryptography>=1.3.4 in c:\\data_science\\lib\\site-packages (from urllib3[secure,socks]~=1.26->selenium) (3.4.7)\n",
      "Requirement already satisfied: certifi in c:\\data_science\\lib\\site-packages (from urllib3[secure,socks]~=1.26->selenium) (2020.12.5)\n",
      "Requirement already satisfied: pyOpenSSL>=0.14 in c:\\data_science\\lib\\site-packages (from urllib3[secure,socks]~=1.26->selenium) (20.0.1)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\data_science\\lib\\site-packages (from urllib3[secure,socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: six>=1.5.2 in c:\\data_science\\lib\\site-packages (from pyOpenSSL>=0.14->urllib3[secure,socks]~=1.26->selenium) (1.15.0)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\data_science\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.13.0)\n"
     ]
    }
   ],
   "source": [
    "#Let's first install selenium\n",
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b19dfc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets import all the required libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "\n",
    "import time\n",
    "\n",
    "#Importing requests\n",
    "import requests\n",
    "\n",
    "# importing regex\n",
    "import re\n",
    "\n",
    "# Importing required Exceptions\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from selenium.common.exceptions import NoSuchElementException,ElementNotInteractableException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2bf1efa",
   "metadata": {},
   "source": [
    "# 1. Scrape the details of most viewed videos on YouTube from Wikipedia.\n",
    "Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\n",
    "You need to find following details:\n",
    "A) Rank\n",
    "B) Name\n",
    "C) Artist\n",
    "D) Upload date\n",
    "E) Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3123fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets connect to the web driver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\X1\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc421a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome('chromedriver.exe')\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36c189a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(' https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e002eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty lists for the attributes\n",
    "Rank=[]\n",
    "Name=[] \n",
    "Artist=[] \n",
    "Upload_date=[]\n",
    "Views=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c61e7a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4079914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1.', '2.', '3.', '4.', '5.', '6.', '7.', '8.', '9.', '10.', '11.', '12.', '13.', '14.', '15.', '16.', '17.', '18.', '19.', '20.', '21.', '22.', '23.', '24.', '25.', '26.', '27.', '28.', '29.', '30.']\n"
     ]
    }
   ],
   "source": [
    "Rank=[]\n",
    "try:\n",
    "    ranks=driver.find_elements_by_xpath(\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[1]\")\n",
    "    for i in ranks:  \n",
    "        Rank.append(i.text)\n",
    "        \n",
    "except NoSuchElementException:\n",
    "    Rank.append(\"no detail available\")\n",
    "except StaleElementReferenceException:\n",
    "    Rank.append(\"no detail available\")\n",
    "print(Rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c63eacd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\"Baby Shark Dance\"[3]', '\"Despacito\"[6]', '\"Johny Johny Yes Papa\"[12]', '\"Shape of You\"[13]', '\"See You Again\"[15]', '\"Bath Song\"[20]', '\"Phonics Song with Two Words\"[21]', '\"Uptown Funk\"[22]', '\"Learning Colors – Colorful Eggs on a Farm\"[23]', '\"Masha and the Bear – Recipe for Disaster\"[24]', '\"Gangnam Style\"[25]', '\"Wheels on the Bus\"[30]', '\"Dame Tu Cosita\"[31]', '\"Sugar\"[32]', '\"Roar\"[33]', '\"Counting Stars\"[34]', '\"Sorry\"[35]', '\"Thinking Out Loud\"[36]', '\"Axel F\"[37]', '\"Girls Like You\"[38]', '\"Faded\"[39]', '\"Dark Horse\"[40]', '\"Baa Baa Black Sheep\"[41]', '\"Let Her Go\"[42]', '\"Bailando\"[43]', '\"Lean On\"[44]', '\"Shake It Off\"[45]', '\"Perfect\"[46]', '\"Waka Waka (This Time for Africa)\"[47]', '\"Mi Gente\"[48]']\n"
     ]
    }
   ],
   "source": [
    "#scrapping the name of the video\n",
    "Name=[]\n",
    "try:\n",
    "    names=driver.find_elements_by_xpath(\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[2]\")\n",
    "    for i in names:\n",
    "        Name.append(i.text)\n",
    "        \n",
    "except NoSuchElementException:\n",
    "    Name.append(\"no detail available\")\n",
    "except StaleElementReferenceException:\n",
    "    Name.append(\"no detail available\")\n",
    "print(Name)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb724b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Pinkfong Baby Shark - Kids' Songs & Stories\", 'Luis Fonsi', 'LooLoo Kids', 'Ed Sheeran', 'Wiz Khalifa', 'Cocomelon – Nursery Rhymes', 'ChuChu TV', 'Mark Ronson', 'Miroshka TV', 'Get Movies', 'Psy', 'Cocomelon – Nursery Rhymes', 'El Chombo', 'Maroon 5', 'Katy Perry', 'OneRepublic', 'Justin Bieber', 'Ed Sheeran', 'Crazy Frog', 'Maroon 5', 'Alan Walker', 'Katy Perry', 'Cocomelon – Nursery Rhymes', 'Passenger', 'Enrique Iglesias', 'Major Lazer', 'Taylor Swift', 'Ed Sheeran', 'Shakira', 'J Balvin']\n"
     ]
    }
   ],
   "source": [
    "#scrapping the details of artist\n",
    "Artist=[]\n",
    "try:\n",
    "    artists=driver.find_elements_by_xpath(\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[3]\")\n",
    "    for i in artists:\n",
    "        Artist.append(i.text)\n",
    "        \n",
    "except NoSuchElementException:\n",
    "    Artist.append(\"no detail available\")\n",
    "except StaleElementReferenceException:\n",
    "    Artist.append(\"no detail available\")\n",
    "print(Artist)          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf0e7521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['June 17, 2016', 'January 12, 2017', 'October 8, 2016', 'January 30, 2017', 'April 6, 2015', 'May 2, 2018', 'March 6, 2014', 'November 19, 2014', 'February 27, 2018', 'January 31, 2012', 'July 15, 2012', 'May 24, 2018', 'April 5, 2018', 'January 14, 2015', 'September 5, 2013', 'May 31, 2013', 'October 22, 2015', 'October 7, 2014', 'June 16, 2009', 'May 31, 2018', 'December 3, 2015', 'February 20, 2014', 'June 25, 2018', 'July 25, 2012', 'April 11, 2014', 'March 22, 2015', 'August 18, 2014', 'November 9, 2017', 'June 4, 2010', 'June 29, 2017']\n"
     ]
    }
   ],
   "source": [
    "#scrapping the details of upload date\n",
    "Upload_date=[]\n",
    "try:\n",
    "    upload_dates_list=driver.find_elements_by_xpath(\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[5]\")\n",
    "    for i in upload_dates_list:\n",
    "        Upload_date.append(i.text)\n",
    "        \n",
    "except NoSuchElementException:\n",
    "    Upload_date.append(\"no detail available\")\n",
    "except StaleElementReferenceException:\n",
    "    Upload_date.append(\"no detail available\")\n",
    "print(Upload_date)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c5e6a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10.70', '7.85', '6.35', '5.72', '5.51', '5.38', '4.63', '4.57', '4.57', '4.50', '4.43', '4.07', '3.94', '3.70', '3.58', '3.58', '3.55', '3.45', '3.36', '3.29', '3.28', '3.27', '3.24', '3.23', '3.21', '3.21', '3.17', '3.17', '3.14', '3.08']\n"
     ]
    }
   ],
   "source": [
    "#scrapping the details of views\n",
    "Views=[]\n",
    "try:\n",
    "    view=driver.find_elements_by_xpath(\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[4]\")\n",
    "    for i in view:\n",
    "        Views.append(i.text)\n",
    "        \n",
    "except NoSuchElementException:\n",
    "    Views.append(\"no detail available\")\n",
    "except StaleElementReferenceException:\n",
    "    Views.append(\"no detail available\")\n",
    "print(Views)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a7d4c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "640f3ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Rank                                             Name                                       Artist        Upload Date  Views\n",
      "0    1.                            \"Baby Shark Dance\"[3]  Pinkfong Baby Shark - Kids' Songs & Stories      June 17, 2016  10.70\n",
      "1    2.                                   \"Despacito\"[6]                                   Luis Fonsi   January 12, 2017   7.85\n",
      "2    3.                       \"Johny Johny Yes Papa\"[12]                                  LooLoo Kids    October 8, 2016   6.35\n",
      "3    4.                               \"Shape of You\"[13]                                   Ed Sheeran   January 30, 2017   5.72\n",
      "4    5.                              \"See You Again\"[15]                                  Wiz Khalifa      April 6, 2015   5.51\n",
      "5    6.                                  \"Bath Song\"[20]                   Cocomelon – Nursery Rhymes        May 2, 2018   5.38\n",
      "6    7.                \"Phonics Song with Two Words\"[21]                                    ChuChu TV      March 6, 2014   4.63\n",
      "7    8.                                \"Uptown Funk\"[22]                                  Mark Ronson  November 19, 2014   4.57\n",
      "8    9.  \"Learning Colors – Colorful Eggs on a Farm\"[23]                                  Miroshka TV  February 27, 2018   4.57\n",
      "9   10.   \"Masha and the Bear – Recipe for Disaster\"[24]                                   Get Movies   January 31, 2012   4.50\n",
      "10  11.                              \"Gangnam Style\"[25]                                          Psy      July 15, 2012   4.43\n",
      "11  12.                          \"Wheels on the Bus\"[30]                   Cocomelon – Nursery Rhymes       May 24, 2018   4.07\n",
      "12  13.                             \"Dame Tu Cosita\"[31]                                    El Chombo      April 5, 2018   3.94\n",
      "13  14.                                      \"Sugar\"[32]                                     Maroon 5   January 14, 2015   3.70\n",
      "14  15.                                       \"Roar\"[33]                                   Katy Perry  September 5, 2013   3.58\n",
      "15  16.                             \"Counting Stars\"[34]                                  OneRepublic       May 31, 2013   3.58\n",
      "16  17.                                      \"Sorry\"[35]                                Justin Bieber   October 22, 2015   3.55\n",
      "17  18.                          \"Thinking Out Loud\"[36]                                   Ed Sheeran    October 7, 2014   3.45\n",
      "18  19.                                     \"Axel F\"[37]                                   Crazy Frog      June 16, 2009   3.36\n",
      "19  20.                             \"Girls Like You\"[38]                                     Maroon 5       May 31, 2018   3.29\n",
      "20  21.                                      \"Faded\"[39]                                  Alan Walker   December 3, 2015   3.28\n",
      "21  22.                                 \"Dark Horse\"[40]                                   Katy Perry  February 20, 2014   3.27\n",
      "22  23.                        \"Baa Baa Black Sheep\"[41]                   Cocomelon – Nursery Rhymes      June 25, 2018   3.24\n",
      "23  24.                                 \"Let Her Go\"[42]                                    Passenger      July 25, 2012   3.23\n",
      "24  25.                                   \"Bailando\"[43]                             Enrique Iglesias     April 11, 2014   3.21\n",
      "25  26.                                    \"Lean On\"[44]                                  Major Lazer     March 22, 2015   3.21\n",
      "26  27.                               \"Shake It Off\"[45]                                 Taylor Swift    August 18, 2014   3.17\n",
      "27  28.                                    \"Perfect\"[46]                                   Ed Sheeran   November 9, 2017   3.17\n",
      "28  29.           \"Waka Waka (This Time for Africa)\"[47]                                      Shakira       June 4, 2010   3.14\n",
      "29  30.                                   \"Mi Gente\"[48]                                     J Balvin      June 29, 2017   3.08\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('expand_frame_repr', False)\n",
    "#preparing dataframe\n",
    "videos=pd.DataFrame({\"Rank\":Rank,\"Name\":Name,\"Artist\":Artist,\"Upload Date\":Upload_date,\"Views\":Views})\n",
    "print(videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b785061",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41474bb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "edd2464f",
   "metadata": {},
   "source": [
    "# 2. Scrape the details team India’s international fixtures from bcci.tv.\n",
    "Url = https://www.bcci.tv/.\n",
    "You need to find following details:\n",
    "A) Match title (I.e. 1\n",
    "st ODI)\n",
    "B) Series\n",
    "C) Place\n",
    "D) Date\n",
    "E) Time\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ce86e461",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets connect to the web driver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\X1\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e7ab25e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome('chromedriver.exe')\n",
    "driver.get(' https://www.bcci.tv/.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7213af2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#going to internation fixtures page\n",
    "fixtures=driver.find_element_by_xpath(\"/html/body/nav/div[1]/div[2]/ul[1]/li[2]/a\")\n",
    "\n",
    "driver.get(fixtures.get_attribute('href'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1c8c84d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"390f56120c347b985b63a4dacdb4636c\", element=\"0c85dba8-a8c5-4ed2-88bd-f746d09735c2\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"390f56120c347b985b63a4dacdb4636c\", element=\"e0111c3b-5f3a-4953-a850-17153b33092a\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"390f56120c347b985b63a4dacdb4636c\", element=\"5c39415d-3a0f-465a-aa08-842454ccad88\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"390f56120c347b985b63a4dacdb4636c\", element=\"d5185143-e874-4aa7-9068-d88502348cbd\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"390f56120c347b985b63a4dacdb4636c\", element=\"b16c6120-03ba-475b-8a5d-a629391b4d43\")>]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets extract all the tags having Match titles.\n",
    "titles=driver.find_elements_by_xpath(\"//span[@class='matchOrderText ng-binding ng-scope']\")\n",
    "titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d05d2337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1st T20I -', '2nd T20I -', '3rd T20I -', '4th T20I -', '5th T20I -']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now the text of the match titles are inside the tags extracted above.\n",
    "Match_Titles=[]\n",
    "for i in titles:\n",
    "    title=i.text\n",
    "    Match_Titles.append(title)\n",
    "Match_Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e953f060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"390f56120c347b985b63a4dacdb4636c\", element=\"9d698972-337f-4437-ac82-58d654e49622\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"390f56120c347b985b63a4dacdb4636c\", element=\"fdc3e553-0d36-487d-9153-c1671694691b\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"390f56120c347b985b63a4dacdb4636c\", element=\"d38da770-c72e-431a-8a14-c7e0e8a76eb7\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"390f56120c347b985b63a4dacdb4636c\", element=\"c86fbf90-dc91-4de5-a573-726b994860e1\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"390f56120c347b985b63a4dacdb4636c\", element=\"229c3495-b6be-48be-8922-6dbd58943153\")>]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets extract all the tags having series\n",
    "series=driver.find_elements_by_xpath(\"//span[@class='ng-binding']\")\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "aa0a10ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SOUTH AFRICA TOUR OF INDIA T20 SERIES 2022',\n",
       " 'SOUTH AFRICA TOUR OF INDIA T20 SERIES 2022',\n",
       " 'SOUTH AFRICA TOUR OF INDIA T20 SERIES 2022',\n",
       " 'SOUTH AFRICA TOUR OF INDIA T20 SERIES 2022',\n",
       " 'SOUTH AFRICA TOUR OF INDIA T20 SERIES 2022']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now the text of the series are inside the tags extracted above.\n",
    "Series=[]\n",
    "for i in series:\n",
    "    sr=i.text\n",
    "    Series.append(sr)\n",
    "Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cbf4de4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"390f56120c347b985b63a4dacdb4636c\", element=\"e871bf3a-d298-4fe4-aa27-fcd0d2ebdacc\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"390f56120c347b985b63a4dacdb4636c\", element=\"f56a407e-74bf-4d7c-9f59-3b97e502751d\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"390f56120c347b985b63a4dacdb4636c\", element=\"5405e426-a350-4e56-95bb-5f9e75679445\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"390f56120c347b985b63a4dacdb4636c\", element=\"477b2258-635c-4ba5-b813-076cca105060\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"390f56120c347b985b63a4dacdb4636c\", element=\"8d430a7c-7763-4913-96a5-812bc27cef0a\")>]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "place=driver.find_elements_by_xpath(\"//div[@class='fix-place ng-binding ng-scope']\")\n",
    "place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bd4b8632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Arun Jaitley Stadium, Delhi',\n",
       " 'Barabati Stadium, Cuttack',\n",
       " 'Dr YS Rajasekhara Reddy ACA-VDCA Cricket Stadium, Visakhapatnam',\n",
       " 'Saurashtra Cricket Association Stadium, Rajkot',\n",
       " 'M Chinnaswamy Stadium, Bengaluru']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Places=[]\n",
    "for i in place:\n",
    "    p=i.text\n",
    "    Places.append(p[11:])\n",
    "Places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f7465a0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"390f56120c347b985b63a4dacdb4636c\", element=\"08a7e557-91b8-4ae5-a0b8-3246a9f9ce2d\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"390f56120c347b985b63a4dacdb4636c\", element=\"4183e34d-6167-46ff-8f92-f8c341e11143\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"390f56120c347b985b63a4dacdb4636c\", element=\"7add1f8e-bd05-41fc-820f-52bc9b4ad022\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"390f56120c347b985b63a4dacdb4636c\", element=\"14dd3d0b-2d4d-4abe-9b68-89a361ea46de\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"390f56120c347b985b63a4dacdb4636c\", element=\"b40150ba-e1b6-4a0a-b386-6640e7fc34b5\")>]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date=driver.find_elements_by_xpath(\"//h5[@class='ng-binding']\")\n",
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8dce9006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['9 JUN 2022', '12 JUN 2022', '14 JUN 2022', '17 JUN 2022', '19 JUN 2022']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dates=[]\n",
    "for i in date:\n",
    "    d=i.text\n",
    "    Dates.append(d)\n",
    "Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "767eba25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"390f56120c347b985b63a4dacdb4636c\", element=\"39a0a37b-ebe3-48e7-a7be-9331b697f3ab\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"390f56120c347b985b63a4dacdb4636c\", element=\"d144637e-7fd7-4cdb-a763-70728d28fab7\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"390f56120c347b985b63a4dacdb4636c\", element=\"85d015ec-26ae-4d75-8cb8-bbdb23ac1859\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"390f56120c347b985b63a4dacdb4636c\", element=\"34aa5870-0be7-454d-a836-66181b9fab5b\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"390f56120c347b985b63a4dacdb4636c\", element=\"27f3d523-2105-4196-8455-bafe39400f35\")>]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time=driver.find_elements_by_xpath(\"//h5[@class='text-right ng-binding']\")\n",
    "time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1fef172a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['7:00 PM IST', '7:00 PM IST', '7:00 PM IST', '7:00 PM IST', '7:00 PM IST']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Time=[]\n",
    "for i in time:\n",
    "    t=i.text\n",
    "    Time.append(t)\n",
    "Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cb1a1cc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match_Titles</th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Dates</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1st T20I -</td>\n",
       "      <td>SOUTH AFRICA TOUR OF INDIA T20 SERIES 2022</td>\n",
       "      <td>Arun Jaitley Stadium, Delhi</td>\n",
       "      <td>9 JUN 2022</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2nd T20I -</td>\n",
       "      <td>SOUTH AFRICA TOUR OF INDIA T20 SERIES 2022</td>\n",
       "      <td>Barabati Stadium, Cuttack</td>\n",
       "      <td>12 JUN 2022</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3rd T20I -</td>\n",
       "      <td>SOUTH AFRICA TOUR OF INDIA T20 SERIES 2022</td>\n",
       "      <td>Dr YS Rajasekhara Reddy ACA-VDCA Cricket Stadi...</td>\n",
       "      <td>14 JUN 2022</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4th T20I -</td>\n",
       "      <td>SOUTH AFRICA TOUR OF INDIA T20 SERIES 2022</td>\n",
       "      <td>Saurashtra Cricket Association Stadium, Rajkot</td>\n",
       "      <td>17 JUN 2022</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5th T20I -</td>\n",
       "      <td>SOUTH AFRICA TOUR OF INDIA T20 SERIES 2022</td>\n",
       "      <td>M Chinnaswamy Stadium, Bengaluru</td>\n",
       "      <td>19 JUN 2022</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Match_Titles                                      Series                                              Place        Dates         Time\n",
       "0   1st T20I -  SOUTH AFRICA TOUR OF INDIA T20 SERIES 2022                        Arun Jaitley Stadium, Delhi   9 JUN 2022  7:00 PM IST\n",
       "1   2nd T20I -  SOUTH AFRICA TOUR OF INDIA T20 SERIES 2022                          Barabati Stadium, Cuttack  12 JUN 2022  7:00 PM IST\n",
       "2   3rd T20I -  SOUTH AFRICA TOUR OF INDIA T20 SERIES 2022  Dr YS Rajasekhara Reddy ACA-VDCA Cricket Stadi...  14 JUN 2022  7:00 PM IST\n",
       "3   4th T20I -  SOUTH AFRICA TOUR OF INDIA T20 SERIES 2022     Saurashtra Cricket Association Stadium, Rajkot  17 JUN 2022  7:00 PM IST\n",
       "4   5th T20I -  SOUTH AFRICA TOUR OF INDIA T20 SERIES 2022                   M Chinnaswamy Stadium, Bengaluru  19 JUN 2022  7:00 PM IST"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "Matches=pd.DataFrame({'Match_Titles':Match_Titles,'Series':Series,'Place':Places,'Dates':Dates,'Time':Time})\n",
    "Matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cc155b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cce7aee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4020a1d3",
   "metadata": {},
   "source": [
    "# 3. Scrape the details of selenium exception from guru99.com.\n",
    "Url = https://www.guru99.com/\n",
    "You need to find following details:\n",
    "A) Name\n",
    "B) Description\n",
    "Note: - From guru99 home page you have to reach to selenium exception handling page through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5deeb721",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the drivers and url\n",
    "driver=webdriver.Chrome('chromedriver.exe')\n",
    "driver.get('https://www.guru99.com/')\n",
    "driver.maximize_window()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "73e6aee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking on selenium tutorial\n",
    "driver.find_element_by_xpath(\"//*[@id='java_technologies']/li[3]/a\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "bffdb607",
   "metadata": {},
   "outputs": [],
   "source": [
    "#navigate to selenium page\n",
    "exception_handle_link=driver.find_element_by_xpath(\"//a[@title='Selenium Exception Handling (Common Exceptions List)']\")\n",
    "try:\n",
    "    exception_handle_link.click()\n",
    "except ElementNotInteractableException:#handling element not clickable exception\n",
    "    driver.get(exception_handle_link.get_attribute('href'))         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "7fa12ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "#scraping exceptions names\n",
    "name=[]\n",
    "try:\n",
    "    names=driver.find_elements_by_xpath(\"//table[@class='table table-striped']/tbody/tr/td[1]\")\n",
    "    for i in names[1:]:\n",
    "        name.append(i.text)\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "    name.append('No details available')\n",
    "print(len(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7791da65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "#scraping exceptions description\n",
    "desc=[]\n",
    "try:\n",
    "    desc_list=driver.find_elements_by_xpath(\"//table[@class='table table-striped']/tbody/tr/td[2]\")\n",
    "    for i in desc_list[1:]:\n",
    "        desc.append(i.text)\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "    desc.append('No details available')\n",
    "print(len(desc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "82b1783d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Exception_name                                        Description\n",
      "0         ElementNotSelectableException  This Selenium exception occurs when an element...\n",
      "1                NoSuchElementException  This Exception occurs if an element could not ...\n",
      "2                  NoSuchFrameException  This Exception occurs if the frame target to b...\n",
      "3               NoAlertPresentException  This Exception occurs when you switch to no pr...\n",
      "4                 NoSuchWindowException  This Exception occurs if the window target to ...\n",
      "5        StaleElementReferenceException  This Selenium exception occurs happens when th...\n",
      "6              SessionNotFoundException  The WebDriver is acting after you quit the bro...\n",
      "7                      TimeoutException  Thrown when there is not enough time for a com...\n",
      "8                    WebDriverException  This Exception takes place when the WebDriver ...\n",
      "9             ConnectionClosedException  This type of Exception takes place when there ...\n",
      "10     ElementClickInterceptedException  The command may not be completed as the elemen...\n",
      "11      ElementNotInteractableException  This Selenium exception is thrown when any ele...\n",
      "12             ErrorInResponseException  This happens while interacting with the Firefo...\n",
      "13  ErrorHandler.UnknownServerException  Exception is used as a placeholder in case if ...\n",
      "14         ImeActivationFailedException  This expectation will occur when IME engine ac...\n",
      "15             ImeNotAvailableException    It takes place when IME support is unavailable.\n",
      "16         InsecureCertificateException  Navigation made the user agent to hit a certif...\n",
      "17             InvalidArgumentException  It occurs when an argument does not belong to ...\n",
      "18         InvalidCookieDomainException  This happens when you try to add a cookie unde...\n",
      "19          InvalidCoordinatesException  This type of Exception matches an interacting ...\n",
      "20          InvalidElementStateExceptio  It occurs when command can’t be finished when ...\n",
      "21            InvalidSessionIdException  This Exception took place when the given sessi...\n",
      "22       InvalidSwitchToTargetException  This occurs when the frame or window target to...\n",
      "23                  JavascriptException  This issue occurs while executing JavaScript g...\n",
      "24                        JsonException  It occurs when you afford to get the session w...\n",
      "25             NoSuchAttributeException  This kind of Exception occurs when the attribu...\n",
      "26       MoveTargetOutOfBoundsException  It takes place if the target provided to the A...\n",
      "27               NoSuchContextException           ContextAware does mobile device testing.\n",
      "28                NoSuchCookieException  This Exception occurs when no cookie matching ...\n",
      "29                    NotFoundException  This Exception is a subclass of WebDriverExcep...\n",
      "30          RemoteDriverServerException  This Selenium exception is thrown when the ser...\n",
      "31                  ScreenshotException            It is not possible to capture a screen.\n",
      "32           SessionNotCreatedException  It happens when a new session could not be suc...\n",
      "33           UnableToSetCookieException  This occurs if a driver is unable to set a coo...\n",
      "34           UnexpectedTagNameException  Happens if a support class did not get a web e...\n",
      "35              UnhandledAlertException  This expectation occurs when there is an alert...\n",
      "36      UnexpectedAlertPresentException  It occurs when there is the appearance of an u...\n",
      "37               UnknownMethodException  This Exception happens when the requested comm...\n",
      "38          UnreachableBrowserException  This Exception occurs only when the browser is...\n",
      "39          UnsupportedCommandException  This occurs when remote WebDriver does n’t sen...\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('expand_frame_repr', False)\n",
    "#creating dataframe\n",
    "df=pd.DataFrame({\"Exception_name\":name,\n",
    "                \"Description\":desc})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba25ce9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc1889a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fb79a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "317bb062",
   "metadata": {},
   "source": [
    "# 4. Scrape the details of State-wise GDP of India from statisticstime.com.\n",
    "Url = http://statisticstimes.com/\n",
    "You have to find following details:\n",
    "A) Rank\n",
    "B) State\n",
    "C) GSDP(18-19)\n",
    "D) GSDP(17-18)\n",
    "E) Share(2017)\n",
    "F) GDP($ billion)\n",
    "Note: - From statisticstimes home page you have to reach to economy page through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "1051f8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets connect to the web driver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\X1\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "7d5bd167",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome('chromedriver.exe')\n",
    "driver.get('https://www.statisticstimes.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "4e4c864a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty sets.\n",
    "Rank = []\n",
    "State = []\n",
    "GSDP_18_19 = []\n",
    "GSDP_19_20 = []\n",
    "Share_2018= []\n",
    "GDP = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "94278506",
   "metadata": {},
   "outputs": [],
   "source": [
    "#economy button\n",
    "economy=driver.find_element_by_xpath(\"//div[@class='dropdown'][2]/div/a[3]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "327d0f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    economy.click()\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(economy.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "81c6742c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetching gdp of india state link\n",
    "GDP=driver.find_element_by_xpath(\"//ul[@style='list-style-type:none;margin-left:20px;']/li/a\")\n",
    "try:\n",
    "    GDP.click()\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(GDP.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "109caa76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    }
   ],
   "source": [
    "#scraping rank\n",
    "rank=[]\n",
    "try:\n",
    "    ranks=driver.find_elements_by_xpath(\"//td[@class='data1']\")\n",
    "    for i in ranks:\n",
    "        rank.append(i.text)\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "    rank.append('No details available')\n",
    "print(len(rank[0:33]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "30d623c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    }
   ],
   "source": [
    "#scraping States\n",
    "State=[]\n",
    "try:\n",
    "    states=driver.find_elements_by_xpath(\"//td[@class='name']\")\n",
    "    for i in states:\n",
    "        State.append(i.text)\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "    State.append('No details available')\n",
    "print(len(State[0:33]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "c3a0b754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    }
   ],
   "source": [
    "#scraping GSDP(18-19)\n",
    "GSDP_18=[]\n",
    "try:\n",
    "    info=driver.find_elements_by_xpath(\"//td[@class='data sorting_1']\")\n",
    "    for i in info:\n",
    "        GSDP_18.append(i.text)\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "    GSDP_18.append('No details available')\n",
    "print(len(GSDP_18[0:33]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "984fdc35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "308\n"
     ]
    }
   ],
   "source": [
    "GSDP_details=[]\n",
    "try:\n",
    "    info=driver.find_elements_by_xpath(\"//td[@class='data']\")\n",
    "    for i in info:\n",
    "        GSDP_details.append(i.text)\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "    GSDP_details.append('No details available')\n",
    "print(len(GSDP_details))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "cb608be6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-',\n",
       " '13.94%',\n",
       " '399.921',\n",
       " '-',\n",
       " '2,039,074',\n",
       " '1,845,853',\n",
       " '8.63%',\n",
       " '247.629',\n",
       " '1,312,929',\n",
       " '1,215,307',\n",
       " '1,687,818',\n",
       " '8.39%',\n",
       " '240.726',\n",
       " '1,166,817',\n",
       " '1,123,982',\n",
       " '-',\n",
       " '7.96%',\n",
       " '228.290',\n",
       " '-',\n",
       " '1,186,379',\n",
       " '1,631,977',\n",
       " '7.91%',\n",
       " '226.806',\n",
       " '1,156,039',\n",
       " '1,091,077',\n",
       " '1,253,832',\n",
       " '5.77%',\n",
       " '165.556',\n",
       " '793,223',\n",
       " '739,525',\n",
       " '1,020,989',\n",
       " '4.99%',\n",
       " '143.179',\n",
       " '711,627',\n",
       " '677,428',\n",
       " '972,782',\n",
       " '4.57%',\n",
       " '131.083',\n",
       " '672,018',\n",
       " '621,301',\n",
       " '969,604',\n",
       " '4.56%',\n",
       " '130.791',\n",
       " '663,258',\n",
       " '612,828',\n",
       " '906,672',\n",
       " '4.29%',\n",
       " '122.977',\n",
       " '561,801',\n",
       " '522,009',\n",
       " '-',\n",
       " '4.14%',\n",
       " '118.733',\n",
       " '-',\n",
       " '559,412',\n",
       " '856,112',\n",
       " '4.10%',\n",
       " '117.703',\n",
       " '634,408',\n",
       " '590,569',\n",
       " '831,610',\n",
       " '3.89%',\n",
       " '111.519',\n",
       " '572,240',\n",
       " '531,085',\n",
       " '611,804',\n",
       " '2.81%',\n",
       " '80.562',\n",
       " '414,977',\n",
       " '375,651',\n",
       " '574,760',\n",
       " '2.79%',\n",
       " '79.957',\n",
       " '418,868',\n",
       " '397,669',\n",
       " '521,275',\n",
       " '2.58%',\n",
       " '74.098',\n",
       " '396,499',\n",
       " '376,877',\n",
       " '-',\n",
       " '1.67%',\n",
       " '47.982',\n",
       " '-',\n",
       " '234,048',\n",
       " '329,180',\n",
       " '1.61%',\n",
       " '46.187',\n",
       " '243,477',\n",
       " '231,182',\n",
       " '328,598',\n",
       " '1.57%',\n",
       " '45.145',\n",
       " '240,036',\n",
       " '224,986',\n",
       " '-',\n",
       " '1.30%',\n",
       " '37.351',\n",
       " '-',\n",
       " '193,273',\n",
       " '-',\n",
       " '0.83%',\n",
       " '23.690',\n",
       " '-',\n",
       " '112,755',\n",
       " '165,472',\n",
       " '0.81%',\n",
       " '23.369',\n",
       " '124,403',\n",
       " '117,851',\n",
       " '80,449',\n",
       " '0.39%',\n",
       " '11.115',\n",
       " '63,408',\n",
       " '57,787',\n",
       " '55,984',\n",
       " '0.26%',\n",
       " '7.571',\n",
       " '40,583',\n",
       " '36,963',\n",
       " '-',\n",
       " '0.22%',\n",
       " '6.397',\n",
       " '-',\n",
       " '31,192',\n",
       " '38,253',\n",
       " '0.18%',\n",
       " '5.230',\n",
       " '25,093',\n",
       " '23,013',\n",
       " '36,572',\n",
       " '0.18%',\n",
       " '5.086',\n",
       " '26,695',\n",
       " '24,682',\n",
       " '32,496',\n",
       " '0.15%',\n",
       " '4.363',\n",
       " '20,017',\n",
       " '18,722',\n",
       " '31,790',\n",
       " '0.15%',\n",
       " '4.233',\n",
       " '20,673',\n",
       " '19,300',\n",
       " '-',\n",
       " '0.14%',\n",
       " '4.144',\n",
       " '-',\n",
       " '17,647',\n",
       " '-',\n",
       " '0.13%',\n",
       " '3.737',\n",
       " '-',\n",
       " '16,676',\n",
       " '26,503',\n",
       " '0.12%',\n",
       " '3.385',\n",
       " '18,797',\n",
       " '16,478',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '20,351,013',\n",
       " '18,886,957',\n",
       " '',\n",
       " '2,869',\n",
       " '14,569,268',\n",
       " '14,003,316',\n",
       " '-',\n",
       " '13.97%',\n",
       " '-',\n",
       " '1,794,123',\n",
       " '1,659,210',\n",
       " '8.77%',\n",
       " '1,167,776',\n",
       " '1,079,894',\n",
       " '1,495,758',\n",
       " '8.41%',\n",
       " '1,015,735',\n",
       " '979,159',\n",
       " '1,476,983',\n",
       " '8.09%',\n",
       " '1,035,131',\n",
       " '976,948',\n",
       " '-',\n",
       " '7.92%',\n",
       " '-',\n",
       " '1,036,859',\n",
       " '1,150,711',\n",
       " '5.96%',\n",
       " '713,376',\n",
       " '662,432',\n",
       " '916,014',\n",
       " '5.06%',\n",
       " '630,693',\n",
       " '600,433',\n",
       " '881,873',\n",
       " '4.68%',\n",
       " '594,806',\n",
       " '549,481',\n",
       " '875,429',\n",
       " '4.65%',\n",
       " '595,605',\n",
       " '550,584',\n",
       " '827,019',\n",
       " '4.41%',\n",
       " '496,798',\n",
       " '461,903',\n",
       " '-',\n",
       " '4.24%',\n",
       " '-',\n",
       " '513,322',\n",
       " '779,647',\n",
       " '4.22%',\n",
       " '568,265',\n",
       " '529,739',\n",
       " '755,790',\n",
       " '3.99%',\n",
       " '514,983',\n",
       " '477,834',\n",
       " '562,710',\n",
       " '2.91%',\n",
       " '377,276',\n",
       " '340,512',\n",
       " '517,521',\n",
       " '2.83%',\n",
       " '374,015',\n",
       " '354,830',\n",
       " '457,757',\n",
       " '2.56%',\n",
       " '344,437',\n",
       " '327,805',\n",
       " '-',\n",
       " '1.69%',\n",
       " '-',\n",
       " '207,193',\n",
       " '301,242',\n",
       " '1.63%',\n",
       " '218,232',\n",
       " '204,423',\n",
       " '288,041',\n",
       " '1.60%',\n",
       " '210,837',\n",
       " '200,453',\n",
       " '-',\n",
       " '1.33%',\n",
       " '-',\n",
       " '173,211',\n",
       " '143,063',\n",
       " '0.80%',\n",
       " '107,171',\n",
       " '101,534',\n",
       " '-',\n",
       " '0.78%',\n",
       " '-',\n",
       " '91,666',\n",
       " '72,181',\n",
       " '0.40%',\n",
       " '56,810',\n",
       " '51,878',\n",
       " '50,227',\n",
       " '0.27%',\n",
       " '35,980',\n",
       " '32,830',\n",
       " '-',\n",
       " '0.22%',\n",
       " '-',\n",
       " '27,565',\n",
       " '34,823',\n",
       " '0.19%',\n",
       " '22,291',\n",
       " '20,534',\n",
       " '32,833',\n",
       " '0.18%',\n",
       " '23,564',\n",
       " '21,779',\n",
       " '29,148',\n",
       " '0.15%',\n",
       " '18,549',\n",
       " '17,228',\n",
       " '28,391',\n",
       " '0.15%',\n",
       " '17,060',\n",
       " '15,972',\n",
       " '-',\n",
       " '0.15%',\n",
       " '-',\n",
       " '15,381',\n",
       " '-',\n",
       " '0.13%',\n",
       " '-',\n",
       " '15,013',\n",
       " '24,424',\n",
       " '0.13%',\n",
       " '17,797',\n",
       " '15,372',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '17,994,301',\n",
       " '16,704,645',\n",
       " '',\n",
       " '12,681,246',\n",
       " '12,240,380']"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GSDP_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "e7e4c35c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    }
   ],
   "source": [
    "#scraping GSDP(19-20)\n",
    "GSDP_19=GSDP_details[::5][0:33]\n",
    "print(len(GSDP_19))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "0aabb03e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    }
   ],
   "source": [
    "#scraping share 2018\n",
    "Share=GSDP_details[::1][0:33]\n",
    "print(len(Share))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "7f8d96cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    }
   ],
   "source": [
    "#scraping GDP(billion$)\n",
    "GDP_billion=GSDP_details[::2][0:33]\n",
    "print(len(GDP_billion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "0e0e8ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Rank                      State GSDP(18-19) GSDP(19-20) Share_18-19 GDP(Billion_$)\n",
      "0     1                Maharashtra   2,632,792           -           -              -\n",
      "1     2                 Tamil Nadu   1,630,208   1,845,853      13.94%        399.921\n",
      "2     3              Uttar Pradesh   1,584,764   1,687,818     399.921      2,039,074\n",
      "3     4                    Gujarat   1,502,899           -           -          8.63%\n",
      "4     5                  Karnataka   1,493,127   1,631,977   2,039,074      1,312,929\n",
      "5     6                West Bengal   1,089,898   1,253,832   1,845,853      1,687,818\n",
      "6     7                  Rajasthan     942,586   1,020,989       8.63%        240.726\n",
      "7     8             Andhra Pradesh     862,957     972,782     247.629      1,123,982\n",
      "8     9                  Telangana     861,031     969,604   1,312,929          7.96%\n",
      "9    10             Madhya Pradesh     809,592     906,672   1,215,307              -\n",
      "10   11                     Kerala     781,653           -   1,687,818      1,631,977\n",
      "11   12                      Delhi     774,870     856,112       8.39%        226.806\n",
      "12   13                    Haryana     734,163     831,610     240.726      1,091,077\n",
      "13   14                      Bihar     530,363     611,804   1,166,817          5.77%\n",
      "14   15                     Punjab     526,376     574,760   1,123,982        793,223\n",
      "15   16                     Odisha     487,805     521,275           -      1,020,989\n",
      "16   17                      Assam     315,881           -       7.96%        143.179\n",
      "17   18               Chhattisgarh     304,063     329,180     228.290        677,428\n",
      "18   19                  Jharkhand     297,204     328,598           -          4.57%\n",
      "19   20                Uttarakhand     245,895           -   1,186,379        672,018\n",
      "20   21            Jammu & Kashmir     155,956           -   1,631,977        969,604\n",
      "21   22           Himachal Pradesh     153,845     165,472       7.91%        130.791\n",
      "22   23                        Goa      73,170      80,449     226.806        612,828\n",
      "23   24                    Tripura      49,845      55,984   1,156,039          4.29%\n",
      "24   25                 Chandigarh      42,114           -   1,091,077        561,801\n",
      "25   26                 Puducherry      34,433      38,253   1,253,832              -\n",
      "26   27                  Meghalaya      33,481      36,572       5.77%        118.733\n",
      "27   28                     Sikkim      28,723      32,496     165.556        559,412\n",
      "28   29                    Manipur      27,870      31,790     793,223          4.10%\n",
      "29   30                   Nagaland      27,283           -     739,525        634,408\n",
      "30   31          Arunachal Pradesh      24,603           -   1,020,989        831,610\n",
      "31   32                    Mizoram      22,287      26,503       4.99%        111.519\n",
      "32   33  Andaman & Nicobar Islands           -           -     143.179        531,085\n"
     ]
    }
   ],
   "source": [
    "#creatng dataframe\n",
    "df=pd.DataFrame({'Rank':rank[0:33],\n",
    "                'State':State[0:33],\n",
    "                'GSDP(18-19)':GSDP_18[0:33],\n",
    "                'GSDP(19-20)':GSDP_19,\n",
    "                'Share_18-19':Share,\n",
    "                'GDP(Billion_$)':GDP_billion})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbfcd6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24d0b35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e857b35",
   "metadata": {},
   "source": [
    "# 5. Scrape the details of trending repositories on Github.com.\n",
    "Url = https://github.com/\n",
    "You have to find the following details:\n",
    "A) Repository title\n",
    "B) Repository description\n",
    "C) Contributors count\n",
    "D) Language used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "bf6898ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets connect to the web driver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\X1\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "a2f3bd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome('chromedriver.exe')\n",
    "driver.get(\"https://github.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "d32075f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding explore-trending option\n",
    "explore=driver.find_element_by_xpath(\"/html/body/div[1]/header/div/div[2]/nav/ul/li[4]/details/div/ul/li[5]/a\")\n",
    "driver.get(explore.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "329e0d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    }
   ],
   "source": [
    "#scraping repositories title\n",
    "repo_title=[]\n",
    "try:\n",
    "    repos=driver.find_elements_by_xpath(\"//h1[@class='h3 lh-condensed']\")\n",
    "    for i in repos:\n",
    "        repo_title.append(i.text)\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "    repo_title.append('No details available')\n",
    "print(len(repo_title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "c096a3d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    }
   ],
   "source": [
    "#scraping repositories description\n",
    "repo_desc=[]\n",
    "try:\n",
    "    descriptions=driver.find_elements_by_xpath(\"//p[@class='col-9 color-fg-muted my-1 pr-4']\")\n",
    "    for i in descriptions:\n",
    "        repo_desc.append(i.text)\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "    repo_desc.append('No details available')\n",
    "print(len(repo_desc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "b3aa7d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_urls=[]\n",
    "repos=driver.find_elements_by_xpath(\"//h1[@class='h3 lh-condensed']/a\")\n",
    "for i in repos:\n",
    "    repo_urls.append(i.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "bfd419f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Contributors_count=[]\n",
    "Language_used=[]\n",
    "for i in repo_urls:\n",
    "    driver.get(i)\n",
    "    l=[]\n",
    "    try:#scraping contributors count\n",
    "        count=driver.find_element_by_xpath(\"//h2[@class='h4 mb-3']/a[contains(text(),'Contributors')]/span\")\n",
    "        Contributors_count.append(count.text)\n",
    "    except NoSuchElementException:#handling no such element exception\n",
    "        Contributors_count.append('No details available')\n",
    "     #scraping languages used   \n",
    "    languages=driver.find_elements_by_xpath(\"/html/body/div[4]/main/div[3]/div/div[2]/article[1]/div[2]/span[1]/span[2]\")\n",
    "    if languages:    \n",
    "        Language_used.append(i.text)\n",
    "    else:\n",
    "        Language_used.append('No languages used')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "2bfeee6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Title                                        Description Contributors_count      Language_used\n",
      "0                yihong0618 / Kindle_download_helper             Download all your kindle books script.                  8  No languages used\n",
      "1                    papers-we-love / papers-we-love  Papers from the computer science community to ...                255  No languages used\n",
      "2                            borisdayma / dalle-mini   DALL·E Mini - Generate images from a text prompt                 15  No languages used\n",
      "3                                metabase / metabase  The simplest, fastest way to get business inte...                313  No languages used\n",
      "4             sudheerj / reactjs-interview-questions  List of top 500 ReactJS Interview Questions & ...                 68  No languages used\n",
      "5                                    alibaba / GaiaX  GaiaX dynamic template engine is a lightweight...                  7  No languages used\n",
      "6                        saharmor / dalle-playground  A playground to generate images from any text ...                  3  No languages used\n",
      "7                 dortania / OpenCore-Legacy-Patcher                  Experience macOS just like before                 23  No languages used\n",
      "8                    bradtraversy / 50projects50days         50+ mini web projects using HTML, CSS & JS                 28  No languages used\n",
      "9                                    PaperMC / Paper  High performance Spigot fork that aims to fix ...                291  No languages used\n",
      "10                     AI4Finance-Foundation / FinRL  FinRL: The first open-source project for finan...                 59  No languages used\n",
      "11                               realm / realm-swift  Realm is a mobile database: a replacement for ...                129  No languages used\n",
      "12                 LinuxSuRen / remote-jobs-in-china                                        支持远程办公的中国公司                 17  No languages used\n",
      "13                             chakra-ui / chakra-ui  ⚡️ Simple, Modular & Accessible UI Components ...                516  No languages used\n",
      "14                       manateelazycat / lsp-bridge                       Fastest LSP client for Emacs                 33  No languages used\n",
      "15                            Snailclimb / JavaGuide  「Java学习+面试指南」一份涵盖大部分 Java 程序员所需要掌握的核心知识。准备 Jav...                324  No languages used\n",
      "16                                    jina-ai / jina  Build cross-modal and multi-modal applications...                140  No languages used\n",
      "17                              jina-ai / dalle-flow  A Human-in-the-Loop workflow for creating HD i...                  3  No languages used\n",
      "18                                   alibaba / DataX                       DataX是阿里云DataWorks数据集成的开源版本。                 49  No languages used\n",
      "19     GoogleCloudPlatform / cloud-foundation-fabric   End-to-end modular samples for Terraform on GCP.                 58  No languages used\n",
      "20  shimohq / chinese-programmer-wrong-pronunciation                                     中国程序员容易发音错误的单词                 74  No languages used\n",
      "21                                 vuejs / vitepress          Vite & Vue powered static site generator.                 85  No languages used\n",
      "22                        MicrosoftDocs / azure-docs       Open source documentation of Microsoft Azure             5,000+  No languages used\n",
      "23                     digitalocean / nginxconfig.io            ⚙️ NGINX config generator on steroids 💉                 41  No languages used\n",
      "24                                   gin-gonic / gin  Gin is a HTTP web framework written in Go (Gol...                366  No languages used\n"
     ]
    }
   ],
   "source": [
    "#creating dataframe\n",
    "pd.set_option('expand_frame_repr', False)\n",
    "df=pd.DataFrame({'Title':repo_title,\n",
    "                'Description':repo_desc,\n",
    "                'Contributors_count':Contributors_count,\n",
    "                'Language_used':Language_used})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cf52e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6a8fca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "48d3a340",
   "metadata": {},
   "source": [
    "# 6. Scrape the details of top 100 songs on billiboard.com.\n",
    "Url = https:/www.billboard.com/\n",
    "You have to find the following details:\n",
    "A) Song name\n",
    "B) Artist name\n",
    "C) Last week rank\n",
    "D) Peak rank\n",
    "E) Weeks on board\n",
    "Note: - From the home page you have to click on the charts option then hot 100-page link through code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "d0d25aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets connect to the web driver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\X1\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "285eb5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome('chromedriver.exe')\n",
    "driver.get(\"https:/www.billboard.com/ \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "7e7dc171",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking Hot 100 button\n",
    "Hot_100=driver.find_element_by_xpath(\"/html/body/div[3]/header/div[2]/div/nav/ul/li[1]/a\")\n",
    "try:\n",
    "    Hot_100.click()\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(Hot_100.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "f8371ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "#scraping song names\n",
    "song_name=[]\n",
    "\n",
    "try:\n",
    "    names=driver.find_elements_by_xpath(\"//h3[@class='c-title  a-no-trucate a-font-primary-bold-s u-letter-spacing-0021 u-font-size-23@tablet lrv-u-font-size-16 u-line-height-125 u-line-height-normal@mobile-max a-truncate-ellipsis u-max-width-245 u-max-width-230@tablet-only u-letter-spacing-0028@tablet\")\n",
    "    for i in names:\n",
    "        song_name.append(i.text)\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "    song_name.append('No details available')\n",
    "\n",
    "try:\n",
    "    names=driver.find_elements_by_xpath(\"//h3[@class='c-title  a-no-trucate a-font-primary-bold-s u-letter-spacing-0021 lrv-u-font-size-18@tablet lrv-u-font-size-16 u-line-height-125 u-line-height-normal@mobile-max a-truncate-ellipsis u-max-width-330 u-max-width-230@tablet-only']\")\n",
    "    for i in names:\n",
    "        song_name.append(i.text)\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "    song_name.append('No details available')\n",
    "print(len(song_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "003d24cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "#scraping song names\n",
    "artist_name=[]\n",
    "\n",
    "try:\n",
    "    names=driver.find_elements_by_xpath(\"//span[@class='c-label  a-no-trucate a-font-primary-s lrv-u-font-size-14@mobile-max u-line-height-normal@mobile-max u-letter-spacing-0021 lrv-u-display-block a-truncate-ellipsis-2line u-max-width-330 u-max-width-230@tablet-only u-font-size-20@tablet']\")\n",
    "    for i in names:\n",
    "        artist_name.append(i.text)\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "    artist_name.append('No details available')\n",
    "\n",
    "try:\n",
    "    names=driver.find_elements_by_xpath(\"//span[@class='c-label  a-no-trucate a-font-primary-s lrv-u-font-size-14@mobile-max u-line-height-normal@mobile-max u-letter-spacing-0021 lrv-u-display-block a-truncate-ellipsis-2line u-max-width-330 u-max-width-230@tablet-only']\")\n",
    "    for i in names:\n",
    "        artist_name.append(i.text)\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "    artist_name.append('No details available')\n",
    "print(len(artist_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "d557171d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n"
     ]
    }
   ],
   "source": [
    "#scraping last week rank\n",
    "details=[]\n",
    "\n",
    "try:\n",
    "    ranks=driver.find_elements_by_xpath(\"//span[@class='c-label  a-font-primary-bold-l a-font-primary-m@mobile-max u-font-weight-normal@mobile-max lrv-u-padding-tb-050@mobile-max u-font-size-32@tablet']\")\n",
    "    for i in ranks:\n",
    "        details.append(i.text)\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "    details.append('No details available')\n",
    "\n",
    "try:\n",
    "    ranks=driver.find_elements_by_xpath(\"//span[@class='c-label  a-font-primary-m lrv-u-padding-tb-050@mobile-max']\")\n",
    "    for i in ranks:\n",
    "        details.append(i.text)\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "    details.append('No details available')\n",
    "print(len(last_week_rank))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "dd2f2fc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_week_rank=details[::6]\n",
    "len(last_week_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "a7d9113a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping peak rank\n",
    "peak_rank=details[1::6]\n",
    "len(peak_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "b78a8126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping weeks on chart\n",
    "weeks=details[2::6]\n",
    "len(weeks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "dcf43d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Song_Name                    Artist_Name Last_week_rank Peak Weeks_on_chart\n",
      "0   No details available                   Harry Styles              1    1              9\n",
      "1            First Class                    Jack Harlow              2    1              8\n",
      "2             Wait For U  Future Featuring Drake & Tems              3    1              5\n",
      "3        About Damn Time                          Lizzo              5    4              7\n",
      "4             Heat Waves                  Glass Animals              6    1             72\n",
      "..                   ...                            ...            ...  ...            ...\n",
      "95       Love You Better                         Future             84   12              5\n",
      "96           Wild Hearts                    Keith Urban              -   97              1\n",
      "97     Last Night Lonely                      Jon Pardi              -   98              1\n",
      "98              7500 OBO                     Tim McGraw              -   99              1\n",
      "99     Until I Found You                Stephen Sanchez              -  100              1\n",
      "\n",
      "[100 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "#creating dataframe\n",
    "df=pd.DataFrame({'Song_Name':song_name,\n",
    "                'Artist_Name':artist_name,\n",
    "                'Last_week_rank':last_week_rank,\n",
    "                'Peak':peak_rank,\n",
    "                'Weeks_on_chart':weeks})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ad282a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd64b9aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3aa66691",
   "metadata": {},
   "source": [
    "# 7. Scrape the details of Data science recruiters from naukri.com.\n",
    "Url = https://www.naukri.com/\n",
    "You have to find the following details:\n",
    "A) Name\n",
    "B) Designation\n",
    "C) Company\n",
    "D) Skills they hire for\n",
    "E) Location\n",
    "Note: - From naukri.com homepage click on the recruiters option and the on the search pane type Data science and\n",
    "click on search. All this should be done through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "cfcc031b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets connect to the web driver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\X1\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "b5cd4c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome('chromedriver.exe')\n",
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "5ce0f239",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetching jobs url for recruiter page\n",
    "jobs = driver.find_element_by_xpath(\"//a[@title='Search Jobs']\")\n",
    "jobs_url = jobs.get_attribute(\"href\")\n",
    "\n",
    "driver.get(jobs_url)\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "2d0b8759",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetching urls for recruiter page\n",
    "rec = driver.find_element_by_xpath(\"//a[@title='Search Recruiters']\")\n",
    "page_url = rec.get_attribute(\"href\")\n",
    "\n",
    "driver.get(page_url)\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "b71a7c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetching search button,bar xpath and clicking on it\n",
    "search = driver.find_element_by_xpath(\"//div[@class='inpWrap']//input\") \n",
    "search.send_keys(\"Data science \")           \n",
    "but = driver.find_element_by_xpath(\"//button[@class='fl qsbSrch blueBtn']\").click()     \n",
    "time.sleep(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "4b7f1830",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty list\n",
    "Name = []\n",
    "Designation = []\n",
    "Company = []\n",
    "Skills = []\n",
    "Location = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "696baa0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of Names\n",
    "for i in driver.find_elements_by_xpath(\"//span[@class='fl ellipsis']\")[:50]:\n",
    "    Name.append(i.text)\n",
    "time.sleep(5)\n",
    "\n",
    "\n",
    "#Scraping data of Designation\n",
    "for i in driver.find_elements_by_xpath(\"//span[@class='ellipsis clr']\")[:50]:\n",
    "    Designation.append(i.text)\n",
    "time.sleep(5)\n",
    "\n",
    "#Scraping data of company name\n",
    "for i in driver.find_elements_by_xpath(\"//div[@class='vcard']//p[1]/a[2]\")[:50]:\n",
    "    Company.append(i.text)\n",
    "time.sleep(5)\n",
    "    \n",
    "#scraping data of Skills \n",
    "for i in driver.find_elements_by_xpath(\"//div[@class='hireSec highlightable']\")[:50]:\n",
    "    try:\n",
    "        if i.text == \"Not Specified\": raise NoSuchElementException\n",
    "        Skills.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Skills.append('-')\n",
    "    time.sleep(5)\n",
    "\n",
    "#Scraping data of locations\n",
    "for i in driver.find_elements_by_xpath(\"//div[@class='vcard']//p[1]//span\")[:50]:\n",
    "    Location.append(i.text)\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "34e84ad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Designation</th>\n",
       "      <th>Company</th>\n",
       "      <th>Skills</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aakash Harit</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>Data Science Network</td>\n",
       "      <td>Classic ASP Developer, Internet Marketing Prof...</td>\n",
       "      <td>Aakash Harit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shravan Kumar Gaddam</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>Shore Infotech India Pvt. Ltd</td>\n",
       "      <td>.Net, Java, Data Science, Linux Administration...</td>\n",
       "      <td>HR Manager</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MARSIAN Technologies LLP</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>MARSIAN Technologies LLP</td>\n",
       "      <td>Data Science, Artificial Intelligence, Machine...</td>\n",
       "      <td>Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anik Agrawal</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>Enerlytics Software Solutions Pvt Ltd</td>\n",
       "      <td>Mean Stack, javascript, angularjs, mongodb, We...</td>\n",
       "      <td>shravan Kumar Gaddam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>subhas patel</td>\n",
       "      <td>Founder CEO</td>\n",
       "      <td>LibraryXProject</td>\n",
       "      <td>Hadoop, Spark, Digital Strategy, Data Architec...</td>\n",
       "      <td>Company Recruiter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Abhishek - Only Analytics Hiring - India and</td>\n",
       "      <td>Recruitment Lead Consultant</td>\n",
       "      <td>Apidel Technologies Division of Transpower</td>\n",
       "      <td>Analytics, Business Intelligence, Business Ana...</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Institute for Financial Management and Resear</td>\n",
       "      <td>Programme Manager</td>\n",
       "      <td>IFMR</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>MARSIAN Technologies LLP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Balu Ramesh</td>\n",
       "      <td>HR Administrator</td>\n",
       "      <td>Techvantage Systems Pvt Ltd</td>\n",
       "      <td>Machine Learning, algorithms, Go Getter, Compu...</td>\n",
       "      <td>Company HR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Asif Lucknowi</td>\n",
       "      <td>Director</td>\n",
       "      <td>Weupskill- Live Wire India</td>\n",
       "      <td>Technical Training, Software Development, Pres...</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>InstaFinancials</td>\n",
       "      <td>Human Resource</td>\n",
       "      <td>CBL Data Science Private Limited</td>\n",
       "      <td>Software Development, It Sales, Account Manage...</td>\n",
       "      <td>Anik Agrawal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Priyanka Akiri</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>Infinitive Software Solutions</td>\n",
       "      <td>Oracle Dba, Data Science, Data Warehousing, ET...</td>\n",
       "      <td>Company Recruiter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Kalpana Dumpala</td>\n",
       "      <td>Executive Hiring</td>\n",
       "      <td>Innominds Software</td>\n",
       "      <td>Qa, Ui/ux, Java Developer, Java Architect, C++...</td>\n",
       "      <td>Ahmedabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Mubarak</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>MoneyTap</td>\n",
       "      <td>Business Intelligence, Data Warehousing, Data ...</td>\n",
       "      <td>subhas patel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Kushal Rastogi</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>QuantMagnum Technologies Pvt. Ltd.</td>\n",
       "      <td>Office Administration, Hr Administration, tele...</td>\n",
       "      <td>Founder CEO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Mahesh Babu Channa</td>\n",
       "      <td>HR Team Lead</td>\n",
       "      <td>SocialPrachar.com</td>\n",
       "      <td>Social Media, digital media maketing, seo, smm...</td>\n",
       "      <td>UK - (london)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Kapil Devang</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>BISP Solutions</td>\n",
       "      <td>Big Data, Hadoop, Data Analytics, Data Science</td>\n",
       "      <td>Abhishek - Only Analytics Hiring - India and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Dhruv Dev Dubey</td>\n",
       "      <td>Company Recruitment Head</td>\n",
       "      <td>Confidential</td>\n",
       "      <td>Server Administartion, Verilog, Vhdl, Digital ...</td>\n",
       "      <td>Recruitment Lead Consultant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Sakshi Chhikara</td>\n",
       "      <td>Assistant Manager HR</td>\n",
       "      <td>BIZ INFOTECNO PRIVATE LIMITED</td>\n",
       "      <td>React.js, Data Science, Java, Front End, Busin...</td>\n",
       "      <td>Vadodara / Baroda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Ruchi Dhote</td>\n",
       "      <td>Senior Executive Talent Acquisition</td>\n",
       "      <td>Bristlecone India Ltd</td>\n",
       "      <td>Qlikview, Qlik Sense, Microsoft Azure, Power B...</td>\n",
       "      <td>Institute for Financial Management and Resear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Manisha Yadav</td>\n",
       "      <td>HR Executive</td>\n",
       "      <td>Easi Tax</td>\n",
       "      <td>Telecalling, Client Interaction, Marketing, Re...</td>\n",
       "      <td>Programme Manager</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Riya Rajesh</td>\n",
       "      <td>Manager Talent Acquisition</td>\n",
       "      <td>Novelworx Digital Solutions</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Rashmi Bhattacharjee</td>\n",
       "      <td>HR Head</td>\n",
       "      <td>AXESTRACK SOFTWARE SOLUTIONS PRIVATE...</td>\n",
       "      <td>Corporate Sales, Software Development, Softwar...</td>\n",
       "      <td>Balu Ramesh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Faizan Kareem</td>\n",
       "      <td>HR MANAGER</td>\n",
       "      <td>FirstTech Consaltants Pvt.Ltd</td>\n",
       "      <td>Data Analytics, Data Science, Machine Learning...</td>\n",
       "      <td>HR Administrator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Rithika dadwal</td>\n",
       "      <td>HR Recruiter</td>\n",
       "      <td>Affine Analytics</td>\n",
       "      <td>Data Science, Machine Learning, Python, R, Dee...</td>\n",
       "      <td>Trivandrum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Sandhya Khandagale</td>\n",
       "      <td>HR Recruiter</td>\n",
       "      <td>Compumatrice Multimedia Pvt Ltd</td>\n",
       "      <td>Big Data, Data Science, Artificial Intelligenc...</td>\n",
       "      <td>Asif Lucknowi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Shaun Rao</td>\n",
       "      <td>Manager Human Resources</td>\n",
       "      <td>Exela Technologies</td>\n",
       "      <td>Java, Net, Angularjs, Hr, Infrastructure, Mana...</td>\n",
       "      <td>Director</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Azahar Shaikh</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>NEAL ANALYTICS SERVICES PVT LTD</td>\n",
       "      <td>Data Science, Artificial Intelligence, Machine...</td>\n",
       "      <td>Indore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Manas</td>\n",
       "      <td>Lead Talent acquisition</td>\n",
       "      <td>Autumn Leaf Consulting Services Private...</td>\n",
       "      <td>Software Architecture, Vp Engineering, Product...</td>\n",
       "      <td>InstaFinancials</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>kumar</td>\n",
       "      <td>Proprietor</td>\n",
       "      <td>trainin</td>\n",
       "      <td>Data Science, Hadoop, Rpas, Devops, Python, Aw...</td>\n",
       "      <td>Human Resource</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Sunil Vedula</td>\n",
       "      <td>CEO</td>\n",
       "      <td>Nanoprecise Sci Corp</td>\n",
       "      <td>Signal Processing, Machine Learning, Neural Ne...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Rajat Kumar</td>\n",
       "      <td>Founder CEO</td>\n",
       "      <td>R.S Consultancy &amp;amp; Services</td>\n",
       "      <td>Web Technologies, Project Management, Software...</td>\n",
       "      <td>Priyanka Akiri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Jayanth N</td>\n",
       "      <td>Project Manager</td>\n",
       "      <td>Dollarbird Information Services Pvt, Ltd</td>\n",
       "      <td>Data Analytics, Managed Services, Team Leading...</td>\n",
       "      <td>HR Manager</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Avodha</td>\n",
       "      <td>Business Development Associate</td>\n",
       "      <td>Nikitha Palaparthi</td>\n",
       "      <td>Ethical Hacking, Security Operations Center, S...</td>\n",
       "      <td>Hyderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>SREEDHAR</td>\n",
       "      <td>Recruitment Consultant</td>\n",
       "      <td>JOBSMILL BUSINESS SOLUTIONS PRIVATE LIMITED</td>\n",
       "      <td>Data Science, Machine Learning, Big Data Analy...</td>\n",
       "      <td>Kalpana Dumpala</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Priya Khare</td>\n",
       "      <td>Senior Manager</td>\n",
       "      <td>Independent Consultant</td>\n",
       "      <td>Data Science, Artificial Intelligence, analyti...</td>\n",
       "      <td>Executive Hiring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Amit Sharma</td>\n",
       "      <td>Consultant</td>\n",
       "      <td>ASCO consulting</td>\n",
       "      <td>Machine Learning, Artificial Intelligence, Dat...</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Kanan</td>\n",
       "      <td>senior technology instructor</td>\n",
       "      <td>NY INST</td>\n",
       "      <td>C, C++, Artificial Intelligence, Python, Php, ...</td>\n",
       "      <td>Mubarak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Shashikant Chaudhary</td>\n",
       "      <td>HR Recruiter/HR Excutive</td>\n",
       "      <td>3D India Staffing Research &amp;amp; Consulting...</td>\n",
       "      <td>Relationship Management, Retail Sales, Private...</td>\n",
       "      <td>Company HR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Brad</td>\n",
       "      <td>Manager, Technical Recruiting</td>\n",
       "      <td>O.C. Tanner</td>\n",
       "      <td>Data Science, Software Engineering</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Rutuja Pawar</td>\n",
       "      <td>Technical Recruiter</td>\n",
       "      <td>Demand Matrix</td>\n",
       "      <td>Data Science, Big Data Analytics, Digital Mark...</td>\n",
       "      <td>Kushal Rastogi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Madhusudhan Sridhar</td>\n",
       "      <td>Erp Implementer</td>\n",
       "      <td>MADHUSUDHAN SRIDHAR</td>\n",
       "      <td>Data Science, Recruitment, Salary</td>\n",
       "      <td>Company HR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Ankit Sinha</td>\n",
       "      <td>Head Analytics</td>\n",
       "      <td>Suntech Global</td>\n",
       "      <td>B.Tech, Tableau, Statistics, R, Analytics, Tim...</td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Gaurav Chouhan</td>\n",
       "      <td>Chief Technical Officer</td>\n",
       "      <td>Strategic Consulting Lab</td>\n",
       "      <td>Software Development, Business Intelligence, B...</td>\n",
       "      <td>Mahesh Babu Channa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Rashi Kacker</td>\n",
       "      <td>Sr Product Manager</td>\n",
       "      <td>Impel Labs Pvt. Ltd.</td>\n",
       "      <td>Data Science, Node.js, Angularjs</td>\n",
       "      <td>HR Team Lead</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Ashwini</td>\n",
       "      <td>Director Global Delivery</td>\n",
       "      <td>MRP Advisers</td>\n",
       "      <td>Data Science, Media Marketing, Resource Planni...</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Balaji Kolli</td>\n",
       "      <td>Co Founder</td>\n",
       "      <td>Saras Solutions India Pvt Ltd</td>\n",
       "      <td>Data Analysis, Learning, Data Science, Compute...</td>\n",
       "      <td>Kapil Devang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Rajani Nagaraj</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>WildJasmine</td>\n",
       "      <td>Java, Hadoop, R, Machine Learning, Spark, Flum...</td>\n",
       "      <td>HR Manager</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>ROHIT Kumar</td>\n",
       "      <td>Architect</td>\n",
       "      <td>LNT Private Limited</td>\n",
       "      <td>Software Development, Core Java, Unit Testing,...</td>\n",
       "      <td>Bhopal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Amir Chowdhury</td>\n",
       "      <td>Managing Partner</td>\n",
       "      <td>Granular.ai</td>\n",
       "      <td>Machine Learning, Data Science, Product Manage...</td>\n",
       "      <td>Dhruv Dev Dubey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Ravi Dubey</td>\n",
       "      <td>Recruitment Manager</td>\n",
       "      <td>HyrEzy Talent Solutions LLP</td>\n",
       "      <td>Walmart Interra Skeps Expressstores indifi whi...</td>\n",
       "      <td>Company Recruitment Head</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Name                          Designation                                         Company                                             Skills                                       Location\n",
       "0                                    Aakash Harit                           HR Manager                            Data Science Network  Classic ASP Developer, Internet Marketing Prof...                                   Aakash Harit\n",
       "1                            shravan Kumar Gaddam                    Company Recruiter                   Shore Infotech India Pvt. Ltd  .Net, Java, Data Science, Linux Administration...                                     HR Manager\n",
       "2                        MARSIAN Technologies LLP                           Company HR                        MARSIAN Technologies LLP  Data Science, Artificial Intelligence, Machine...                                          Delhi\n",
       "3                                    Anik Agrawal                    Company Recruiter           Enerlytics Software Solutions Pvt Ltd  Mean Stack, javascript, angularjs, mongodb, We...                           shravan Kumar Gaddam\n",
       "4                                    subhas patel                          Founder CEO                                 LibraryXProject  Hadoop, Spark, Digital Strategy, Data Architec...                              Company Recruiter\n",
       "5    Abhishek - Only Analytics Hiring - India and          Recruitment Lead Consultant      Apidel Technologies Division of Transpower  Analytics, Business Intelligence, Business Ana...                       Hyderabad / Secunderabad\n",
       "6   Institute for Financial Management and Resear                    Programme Manager                                            IFMR                                       Data Science                       MARSIAN Technologies LLP\n",
       "7                                     Balu Ramesh                     HR Administrator                     Techvantage Systems Pvt Ltd  Machine Learning, algorithms, Go Getter, Compu...                                     Company HR\n",
       "8                                   Asif Lucknowi                             Director                      Weupskill- Live Wire India  Technical Training, Software Development, Pres...                                           Pune\n",
       "9                                 InstaFinancials                       Human Resource                CBL Data Science Private Limited  Software Development, It Sales, Account Manage...                                   Anik Agrawal\n",
       "10                                 Priyanka Akiri                           HR Manager                   Infinitive Software Solutions  Oracle Dba, Data Science, Data Warehousing, ET...                              Company Recruiter\n",
       "11                                Kalpana Dumpala                     Executive Hiring                              Innominds Software  Qa, Ui/ux, Java Developer, Java Architect, C++...                                      Ahmedabad\n",
       "12                                        Mubarak                           Company HR                                        MoneyTap  Business Intelligence, Data Warehousing, Data ...                                   subhas patel\n",
       "13                                 Kushal Rastogi                           Company HR              QuantMagnum Technologies Pvt. Ltd.  Office Administration, Hr Administration, tele...                                    Founder CEO\n",
       "14                             Mahesh Babu Channa                         HR Team Lead                               SocialPrachar.com  Social Media, digital media maketing, seo, smm...                                  UK - (london)\n",
       "15                                   Kapil Devang                           HR Manager                                  BISP Solutions     Big Data, Hadoop, Data Analytics, Data Science   Abhishek - Only Analytics Hiring - India and\n",
       "16                                Dhruv Dev Dubey             Company Recruitment Head                                    Confidential  Server Administartion, Verilog, Vhdl, Digital ...                    Recruitment Lead Consultant\n",
       "17                                Sakshi Chhikara                 Assistant Manager HR                   BIZ INFOTECNO PRIVATE LIMITED  React.js, Data Science, Java, Front End, Busin...                              Vadodara / Baroda\n",
       "18                                    Ruchi Dhote  Senior Executive Talent Acquisition                           Bristlecone India Ltd  Qlikview, Qlik Sense, Microsoft Azure, Power B...  Institute for Financial Management and Resear\n",
       "19                                  Manisha Yadav                         HR Executive                                        Easi Tax  Telecalling, Client Interaction, Marketing, Re...                              Programme Manager\n",
       "20                                    Riya Rajesh           Manager Talent Acquisition                     Novelworx Digital Solutions                                       Data Science                                        Chennai\n",
       "21                           Rashmi Bhattacharjee                              HR Head         AXESTRACK SOFTWARE SOLUTIONS PRIVATE...  Corporate Sales, Software Development, Softwar...                                    Balu Ramesh\n",
       "22                                  Faizan Kareem                           HR MANAGER                   FirstTech Consaltants Pvt.Ltd  Data Analytics, Data Science, Machine Learning...                               HR Administrator\n",
       "23                                 Rithika dadwal                         HR Recruiter                                Affine Analytics  Data Science, Machine Learning, Python, R, Dee...                                     Trivandrum\n",
       "24                             Sandhya Khandagale                         HR Recruiter                 Compumatrice Multimedia Pvt Ltd  Big Data, Data Science, Artificial Intelligenc...                                  Asif Lucknowi\n",
       "25                                      Shaun Rao              Manager Human Resources                              Exela Technologies  Java, Net, Angularjs, Hr, Infrastructure, Mana...                                       Director\n",
       "26                                  Azahar Shaikh                    Company Recruiter                 NEAL ANALYTICS SERVICES PVT LTD  Data Science, Artificial Intelligence, Machine...                                         Indore\n",
       "27                                          Manas              Lead Talent acquisition      Autumn Leaf Consulting Services Private...  Software Architecture, Vp Engineering, Product...                                InstaFinancials\n",
       "28                                          kumar                           Proprietor                                         trainin  Data Science, Hadoop, Rpas, Devops, Python, Aw...                                 Human Resource\n",
       "29                                   Sunil Vedula                                  CEO                            Nanoprecise Sci Corp  Signal Processing, Machine Learning, Neural Ne...                          Bengaluru / Bangalore\n",
       "30                                    Rajat Kumar                          Founder CEO                  R.S Consultancy &amp; Services  Web Technologies, Project Management, Software...                                 Priyanka Akiri\n",
       "31                                      Jayanth N                      Project Manager        Dollarbird Information Services Pvt, Ltd  Data Analytics, Managed Services, Team Leading...                                     HR Manager\n",
       "32                                         Avodha       Business Development Associate                              Nikitha Palaparthi  Ethical Hacking, Security Operations Center, S...                                      Hyderabad\n",
       "33                                       SREEDHAR               Recruitment Consultant     JOBSMILL BUSINESS SOLUTIONS PRIVATE LIMITED  Data Science, Machine Learning, Big Data Analy...                                Kalpana Dumpala\n",
       "34                                    Priya Khare                       Senior Manager                          Independent Consultant  Data Science, Artificial Intelligence, analyti...                               Executive Hiring\n",
       "35                                    Amit Sharma                           Consultant                                 ASCO consulting  Machine Learning, Artificial Intelligence, Dat...                       Hyderabad / Secunderabad\n",
       "36                                          Kanan         senior technology instructor                                         NY INST  C, C++, Artificial Intelligence, Python, Php, ...                                        Mubarak\n",
       "37                           Shashikant Chaudhary             HR Recruiter/HR Excutive  3D India Staffing Research &amp; Consulting...  Relationship Management, Retail Sales, Private...                                     Company HR\n",
       "38                                           Brad        Manager, Technical Recruiting                                     O.C. Tanner                 Data Science, Software Engineering                          Bengaluru / Bangalore\n",
       "39                                   Rutuja Pawar                  Technical Recruiter                                   Demand Matrix  Data Science, Big Data Analytics, Digital Mark...                                 Kushal Rastogi\n",
       "40                            Madhusudhan Sridhar                      Erp Implementer                             MADHUSUDHAN SRIDHAR                  Data Science, Recruitment, Salary                                     Company HR\n",
       "41                                    Ankit Sinha                       Head Analytics                                  Suntech Global  B.Tech, Tableau, Statistics, R, Analytics, Tim...                                         Mumbai\n",
       "42                                 Gaurav Chouhan              Chief Technical Officer                        Strategic Consulting Lab  Software Development, Business Intelligence, B...                             Mahesh Babu Channa\n",
       "43                                   Rashi Kacker                   Sr Product Manager                            Impel Labs Pvt. Ltd.                   Data Science, Node.js, Angularjs                                   HR Team Lead\n",
       "44                                        Ashwini             Director Global Delivery                                    MRP Advisers  Data Science, Media Marketing, Resource Planni...                       Hyderabad / Secunderabad\n",
       "45                                   Balaji Kolli                           Co Founder                   Saras Solutions India Pvt Ltd  Data Analysis, Learning, Data Science, Compute...                                   Kapil Devang\n",
       "46                                 Rajani Nagaraj                           HR Manager                                     WildJasmine  Java, Hadoop, R, Machine Learning, Spark, Flum...                                     HR Manager\n",
       "47                                    ROHIT Kumar                            Architect                             LNT Private Limited  Software Development, Core Java, Unit Testing,...                                         Bhopal\n",
       "48                                 Amir Chowdhury                     Managing Partner                                     Granular.ai  Machine Learning, Data Science, Product Manage...                                Dhruv Dev Dubey\n",
       "49                                     Ravi Dubey                  Recruitment Manager                     HyrEzy Talent Solutions LLP  Walmart Interra Skeps Expressstores indifi whi...                       Company Recruitment Head"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DATA FRAMEING\n",
    "Naukri=pd.DataFrame({})\n",
    "Naukri['Name'] = Name\n",
    "Naukri['Designation'] = Designation\n",
    "Naukri['Company'] = Company\n",
    "Naukri['Skills'] = Skills\n",
    "Naukri['Location'] = Location\n",
    "#Printing data frame\n",
    "Naukri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4fd717",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd01d56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dcc38bb0",
   "metadata": {},
   "source": [
    "# 8. Scrape the details of Highest selling novels.\n",
    "Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey\u0002compare/\n",
    "You have to find the following details:\n",
    "A) Book name\n",
    "B) Author name\n",
    "C) Volumes sold\n",
    "D) Publisher\n",
    "E) Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e375fde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets connect to the web driver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\X1\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43dc1b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome('chromedriver.exe')\n",
    "#getting the specified url\n",
    "url = \"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare/\"\n",
    "driver.get(url)\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "838a8599",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty list\n",
    "Book_name = []\n",
    "Author = []\n",
    "Volumes_sold = []\n",
    "Publisher = []\n",
    "Genre = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42f4ccff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping data of book names\n",
    "for i in driver.find_elements_by_xpath(\"//tbody//tr/td[2]\"):\n",
    "    Book_name.append(i.text)\n",
    "\n",
    "    \n",
    "#Scraping data of author names\n",
    "for i in driver.find_elements_by_xpath(\"//tbody/tr/td[3]\"):\n",
    "    try:\n",
    "        if i.text == '0' : raise NoSuchElementException\n",
    "        Author.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Author.append('-')\n",
    "time.sleep(1)\n",
    "\n",
    "\n",
    "#Scraping data of volumes sold\n",
    "for i in driver.find_elements_by_xpath(\"//tbody/tr/td[4]\"):\n",
    "    Volumes_sold.append(i.text)\n",
    "\n",
    "    \n",
    "#Scraping data of publisher names\n",
    "for i in driver.find_elements_by_xpath(\"//tbody/tr/td[5]\"):\n",
    "    Publisher.append(i.text)\n",
    "\n",
    "    \n",
    "#Scraping data of genre\n",
    "for i in driver.find_elements_by_xpath(\"//tbody/tr/td[6]\"):\n",
    "    Genre.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8ec0f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA FRAMEING\n",
    "Novel=pd.DataFrame({})\n",
    "Novel['Book Name'] = Book_name\n",
    "Novel['Author'] = Author\n",
    "Novel['Volume sold'] = Volumes_sold\n",
    "Novel['Publisher'] = Publisher\n",
    "Novel['Genre'] = Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8fb69579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Name</th>\n",
       "      <th>Author</th>\n",
       "      <th>Volume sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book Name            Author  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volume sold        Publisher                        Genre  \n",
       "0    5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1    4,475,152       Bloomsbury           Children's Fiction  \n",
       "2    4,200,654       Bloomsbury           Children's Fiction  \n",
       "3    4,179,479       Bloomsbury           Children's Fiction  \n",
       "4    3,758,936     Random House              Romance & Sagas  \n",
       "..         ...              ...                          ...  \n",
       "95     807,311     Random House   General & Literary Fiction  \n",
       "96     794,201          Penguin        Food & Drink: General  \n",
       "97     792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98     791,507            Orion           Biography: General  \n",
       "99     791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Printing data frame\n",
    "Novel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01764ccd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bdf899",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "07b23946",
   "metadata": {},
   "source": [
    "# 9. Scrape the details most watched tv series of all time from imdb.com.\n",
    "Url = https://www.imdb.com/list/ls095964455/\n",
    "You have to find the following details:\n",
    "A) Name\n",
    "B) Year span\n",
    "C) Genre\n",
    "D) Run time\n",
    "E) Ratings\n",
    "F) Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92a3272a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets connect to the web driver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\X1\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03ad74a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome('chromedriver.exe')\n",
    "#getting the specified url\n",
    "url = \"https://www.imdb.com/list/ls095964455/\"\n",
    "driver.get(url)\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b906d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty lists.\n",
    "Name = []\n",
    "Year_span = []\n",
    "Genre = []\n",
    "Run_time = []\n",
    "Ratings = []\n",
    "Votes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "87451498",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of Names\n",
    "for i in driver.find_elements_by_xpath(\"//h3[@class='lister-item-header']/a\"):\n",
    "    Name.append(i.text)\n",
    "\n",
    "    \n",
    "#Scraping data of Year span\n",
    "for i in driver.find_elements_by_xpath(\"//span[@class='lister-item-year text-muted unbold']\"):\n",
    "    Year_span.append(i.text)\n",
    "\n",
    "    \n",
    "#Scraping data of genre\n",
    "for i in driver.find_elements_by_xpath(\"//span[@class='genre']\"):\n",
    "    Genre.append(i.text)\n",
    "\n",
    "    \n",
    "#Scraping data of Run time\n",
    "for i in driver.find_elements_by_xpath(\"//span[@class='runtime']\"):\n",
    "    Run_time.append(i.text)\n",
    "\n",
    "    \n",
    "#Scraping data of Ratings\n",
    "for i in driver.find_elements_by_xpath(\"//div[@class='ipl-rating-star small']//span[2]\"):\n",
    "    Ratings.append(i.text)\n",
    "\n",
    "    \n",
    "#Scraping data of votes\n",
    "for i in driver.find_elements_by_xpath(\"//div[@class='lister-item-content']//p[4]/span[2]\"):\n",
    "    Votes.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ab115d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year Span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run Time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>1,993,265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016– )</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1,027,986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.2</td>\n",
       "      <td>948,941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>283,528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>243,310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>Drama, Fantasy</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.4</td>\n",
       "      <td>48,840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>59,505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005–2020)</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>190,219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7.1</td>\n",
       "      <td>40,267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>228,511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name    Year Span                     Genre  \\\n",
       "0                  Game of Thrones  (2011–2019)  Action, Adventure, Drama   \n",
       "1                  Stranger Things     (2016– )    Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead  (2010–2022)   Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why  (2017–2020)  Drama, Mystery, Thriller   \n",
       "4                          The 100  (2014–2020)    Drama, Mystery, Sci-Fi   \n",
       "..                             ...          ...                       ...   \n",
       "95                           Reign  (2013–2017)            Drama, Fantasy   \n",
       "96  A Series of Unfortunate Events  (2017–2019)  Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds  (2005–2020)     Crime, Drama, Mystery   \n",
       "98           Scream: The TV Series  (2015–2019)      Comedy, Crime, Drama   \n",
       "99      The Haunting of Hill House       (2018)    Drama, Horror, Mystery   \n",
       "\n",
       "   Run Time Ratings      Votes  \n",
       "0    57 min     9.2  1,993,265  \n",
       "1    51 min     8.7  1,027,986  \n",
       "2    44 min     8.2    948,941  \n",
       "3    60 min     7.5    283,528  \n",
       "4    43 min     7.6    243,310  \n",
       "..      ...     ...        ...  \n",
       "95   42 min     7.4     48,840  \n",
       "96   50 min     7.8     59,505  \n",
       "97   42 min     8.1    190,219  \n",
       "98   45 min     7.1     40,267  \n",
       "99  572 min     8.6    228,511  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DATA FRAMEING\n",
    "IMDB=pd.DataFrame({})\n",
    "IMDB['Name'] = Name\n",
    "IMDB['Year Span'] = Year_span\n",
    "IMDB['Genre'] = Genre\n",
    "IMDB['Run Time'] = Run_time\n",
    "IMDB['Ratings'] = Ratings\n",
    "IMDB['Votes'] = Votes\n",
    "IMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4c9761",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3a9787",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "10f241ad",
   "metadata": {},
   "source": [
    "# 10. Details of Datasets from UCI machine learning repositories.\n",
    "Url = https://archive.ics.uci.edu/\n",
    "You have to find the following details:\n",
    "A) Dataset name\n",
    "B) Data type\n",
    "C) Task\n",
    "D) Attribute type\n",
    "E) No of instances\n",
    "F) No of attribute\n",
    "G) Year\n",
    "Note: - from the home page you have to go to the ShowAllDataset page through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6ee675ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets connect to the web driver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\X1\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "27c4eea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome('chromedriver.exe')\n",
    "#getting the specified url\n",
    "url = \"https://archive.ics.uci.edu/\"\n",
    "driver.get(url)\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1468d8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding view all dataset button\n",
    "view_dataset = driver.find_element_by_xpath(\"//tbody[1]//tr/td[2]/span[2]/a\")    \n",
    "page_url = view_dataset.get_attribute(\"href\")\n",
    "driver.get(page_url)\n",
    "time.sleep(5)\n",
    "\n",
    "#Getting page urls containing list of all datasets\n",
    "all_lst = driver.find_element_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[1]/tbody/tr/td[2]/p/a\")  \n",
    "lst_url = all_lst.get_attribute(\"href\")           \n",
    "driver.get(lst_url)\n",
    "time.sleep(5)\n",
    "\n",
    "#fetching url for each dataset\n",
    "data_url = driver.find_elements_by_xpath(\"//p[@class='normal']//b/a\")    \n",
    "\n",
    "urls = []     \n",
    "for i in data_url:\n",
    "    urls.append(i.get_attribute(\"href\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ba0144dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty list\n",
    "Data_name = []\n",
    "Data_type = []\n",
    "Task = []\n",
    "Attr_type = []\n",
    "Instances = []\n",
    "n_attributes = []\n",
    "Year = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8c2dc262",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping requiredinfo from urls\n",
    "for i in urls:\n",
    "    driver.get(i)\n",
    "    time.sleep(3)\n",
    "    \n",
    "    \n",
    "    #Scraping Dataset name\n",
    "    try: \n",
    "        ds_name = driver.find_element_by_xpath(\"//span[@class='heading']\")\n",
    "        Data_name.append(ds_name.text)\n",
    "    except NoSuchElementException:\n",
    "        Data_name.append('-')\n",
    "    time.sleep(1)\n",
    "    \n",
    "    \n",
    "    #Scraping data type\n",
    "    try:\n",
    "        dtype = driver.find_element_by_xpath(\"//table[@border='1']//tbody/tr/td[2]\")\n",
    "        if dtype.text == \"N/A\": raise NoSuchElementException\n",
    "        Data_type.append(dtype.text)\n",
    "    except NoSuchElementException:\n",
    "        Data_type.append('-')\n",
    "    time.sleep(1)\n",
    "    \n",
    "    \n",
    "    #Scraping Attribute type\n",
    "    try:\n",
    "        atype = driver.find_element_by_xpath(\"//table[@border='1']//tbody/tr[2]/td[2]\")\n",
    "        if atype.text == \"N/A\": raise NoSuchElementException\n",
    "        Attr_type.append(atype.text)\n",
    "    except NoSuchElementException:\n",
    "        Attr_type.append('-')\n",
    "    time.sleep(1)\n",
    "    \n",
    "    \n",
    "    #scraping Task\n",
    "    try:\n",
    "        task = driver.find_element_by_xpath(\"//table[@border='1']//tbody/tr[3]/td[2]\")\n",
    "        if task.text == \"N/A\": raise NoSuchElementException\n",
    "        Task.append(task.text)\n",
    "    except NoSuchElementException:\n",
    "        Task.append('-')\n",
    "    time.sleep(1)\n",
    "    \n",
    "    \n",
    "    #Scraping No of instances\n",
    "    try:\n",
    "        inst = driver.find_element_by_xpath(\"//table[@border='1']//tbody/tr/td[4]\")\n",
    "        if inst.text == \"N/A\": raise NoSuchElementException\n",
    "        Instances.append(inst.text)\n",
    "    except NoSuchElementException:\n",
    "        Instances.append('-')\n",
    "    time.sleep(1)\n",
    "    \n",
    "    \n",
    "    #Scraping  No of attribute\n",
    "    try:\n",
    "        attr = driver.find_element_by_xpath(\"//table[@border='1']//tbody/tr[2]/td[4]\")\n",
    "        if attr.text == \"N/A\": raise NoSuchElementException\n",
    "        n_attributes.append(attr.text)\n",
    "    except NoSuchElementException:\n",
    "        n_attributes.append('-')\n",
    "    time.sleep(1)\n",
    "    \n",
    "    \n",
    "    #scraping year\n",
    "    try:\n",
    "        year = driver.find_element_by_xpath(\"//table[@border='1']//tbody/tr[2]/td[6]\")\n",
    "        if year.text == \"N/A\": raise NoSuchElementException\n",
    "        Year.append(year.text[:4])\n",
    "    except NoSuchElementException:\n",
    "        Year.append('-')\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2172c087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data Name</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute type</th>\n",
       "      <th>No of instance</th>\n",
       "      <th>No of attributes</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.4 GHZ Indoor Channel Measurements Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>7840</td>\n",
       "      <td>5</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3D Road Network (North Jutland, Denmark) Data Set</td>\n",
       "      <td>Sequential, Text</td>\n",
       "      <td>Regression, Clustering</td>\n",
       "      <td>Real</td>\n",
       "      <td>434874</td>\n",
       "      <td>4</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3W dataset Data Set</td>\n",
       "      <td>Multivariate, Time-Series</td>\n",
       "      <td>Classification, Clustering</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>1984</td>\n",
       "      <td>8</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9mers from cullpdb Data Set</td>\n",
       "      <td>Sequential</td>\n",
       "      <td>Classification, Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>158716</td>\n",
       "      <td>4</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>: Simulated Data set of Iraqi tourism places D...</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification, Clustering</td>\n",
       "      <td>-</td>\n",
       "      <td>232</td>\n",
       "      <td>16</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>Youtube cookery channels viewers comments in H...</td>\n",
       "      <td>Multivariate, Text</td>\n",
       "      <td>Classification</td>\n",
       "      <td>-</td>\n",
       "      <td>9800</td>\n",
       "      <td>3</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>YouTube Multiview Video Games Dataset Data Set</td>\n",
       "      <td>Multivariate, Text</td>\n",
       "      <td>Classification, Clustering</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>120000</td>\n",
       "      <td>1000000</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>YouTube Spam Collection Data Set</td>\n",
       "      <td>Text</td>\n",
       "      <td>Classification</td>\n",
       "      <td>-</td>\n",
       "      <td>1956</td>\n",
       "      <td>5</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>Z-Alizadeh Sani Data Set</td>\n",
       "      <td>-</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>303</td>\n",
       "      <td>56</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>Zoo Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>101</td>\n",
       "      <td>17</td>\n",
       "      <td>1990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>622 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Data Name  \\\n",
       "0         2.4 GHZ Indoor Channel Measurements Data Set   \n",
       "1    3D Road Network (North Jutland, Denmark) Data Set   \n",
       "2                                  3W dataset Data Set   \n",
       "3                          9mers from cullpdb Data Set   \n",
       "4    : Simulated Data set of Iraqi tourism places D...   \n",
       "..                                                 ...   \n",
       "617  Youtube cookery channels viewers comments in H...   \n",
       "618     YouTube Multiview Video Games Dataset Data Set   \n",
       "619                   YouTube Spam Collection Data Set   \n",
       "620                           Z-Alizadeh Sani Data Set   \n",
       "621                                       Zoo Data Set   \n",
       "\n",
       "                     Data Type                        Task  \\\n",
       "0                 Multivariate              Classification   \n",
       "1             Sequential, Text      Regression, Clustering   \n",
       "2    Multivariate, Time-Series  Classification, Clustering   \n",
       "3                   Sequential  Classification, Regression   \n",
       "4                 Multivariate  Classification, Clustering   \n",
       "..                         ...                         ...   \n",
       "617         Multivariate, Text              Classification   \n",
       "618         Multivariate, Text  Classification, Clustering   \n",
       "619                       Text              Classification   \n",
       "620                          -              Classification   \n",
       "621               Multivariate              Classification   \n",
       "\n",
       "           Attribute type No of instance No of attributes  Year  \n",
       "0                    Real           7840                5  2018  \n",
       "1                    Real         434874                4  2013  \n",
       "2           Integer, Real           1984                8  2019  \n",
       "3                    Real         158716                4  2021  \n",
       "4                       -            232               16  2020  \n",
       "..                    ...            ...              ...   ...  \n",
       "617                     -           9800                3  2019  \n",
       "618         Integer, Real         120000          1000000  2013  \n",
       "619                     -           1956                5  2017  \n",
       "620         Integer, Real            303               56  2017  \n",
       "621  Categorical, Integer            101               17  1990  \n",
       "\n",
       "[622 rows x 7 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DATA FRAMEING\n",
    "UCI=pd.DataFrame({})\n",
    "UCI['Data Name'] = Data_name\n",
    "UCI['Data Type'] = Data_type\n",
    "UCI['Task'] = Task\n",
    "UCI['Attribute type'] = Attr_type\n",
    "UCI['No of instance'] = Instances\n",
    "UCI['No of attributes'] = n_attributes\n",
    "UCI['Year'] = Year\n",
    "\n",
    "#Printing dataframe\n",
    "UCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426d43bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f97824ee",
   "metadata": {},
   "source": [
    "# THE END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8090f21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
